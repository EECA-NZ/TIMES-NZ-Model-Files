"""
This module takes the metadata file generated by reading tomls

And automatically outputs markdown documentation
"""

from pathlib import Path

import numpy as np
import pandas as pd
from prepare_times_nz.utilities.filepaths import STAGE_0_DATA, TIMES_LOCATION

# CONSTANTS


input_file = STAGE_0_DATA / "config_metadata.csv"
OUTPUT_LOCATION = TIMES_LOCATION / "docs/model_structure_docs"


def create_workbook_categories(df):
    """
    Expands the metadata csv to categorise each workbook

    Uses a dict of workbook prefixes and relevant labels

    That dict currently stored in this function, could move elsewhere
    """

    workbook_categories = {
        # Manual categorising of workbook names, based on address prefixes
        "SysSettings": "Settings",
        "VT_": "Base year (Historical) data",
        "BY_Trans": "Base year (Historical) data",
        "SuppXLS/Scen_": "Standard scenario",
        "SuppXLS/Demands": "Demand scenario",
        "SuppXLS/Trades/ScenTrade_": "Inter-regional trade",
        "SubRES_TMPL/SubRES_": "SubRES: Optional expansion of Reference Energy System",
    }

    # set default category. We also order these by their order in the input dict
    df["Category"] = "Other"
    df["Order"] = 10
    n = 0
    for prefix, category in workbook_categories.items():
        # otherwise map category based on workbook name. Room to expand these
        # Should go from less -> more detailed if clash,
        # as each subsequent entry will overwrite previous if applicable
        df["Category"] = np.where(
            df["WorkBookName"].str.startswith(prefix), category, df["Category"]
        )
        df["Order"] = np.where(
            df["WorkBookName"].str.startswith(prefix), n, df["Order"]
        )
        n += 1

    df = df.sort_values("Order")

    return df


# pylint: disable =  too-many-locals
def generate_tag_markdown(df):
    """

    Generates all our markdown.

    Should probably split this function up a bit

    """

    index_filename = "model-structure.md"

    index_text = []

    categories = df["Category"].unique().tolist()

    # Some header text for the main document

    index_text.append("[Back to Main Documentation](../README.md)")
    index_text.append("# TIMES-NZ model structure documentation")
    index_text.append("\n")
    index_text.append(
        "This document describes every input for the TIMES-NZ model structure and topology."
    )
    index_text.append(
        "All model inputs are contained in excel files generated by `PREPARE-TIMES-NZ`, "
    )
    index_text.append(
        "and this documentation is automatically generated whenever there is an update."
    )
    index_text.append(
        "It is intended to guide developers and users to better understand all TIMES-NZ input data."
    )
    index_text.append("\n")
    index_text.append("Documents are organised by broad category.")

    for category in categories:

        index_text.append(f"### {category}")
        index_text.append("\n")

        df_c = df[df["Category"] == category]
        workbooks = df_c["WorkBookName"].unique().tolist()

        for w in workbooks:

            # data
            df_w = df_c[df_c["WorkBookName"] == w]

            # filanem for this markdown file
            filename = f"{w}.md"
            filename = filename.replace("/", "_")

            # add link to index file text
            index_text.append(f" - [{w}.xlsx](model_structure_docs/{filename})")

            workbook_text = []

            workbook_text.append(
                f"[Back to Model Structure Index](../{index_filename})"
            )

            workbook_text.append(f"## {w}.xlsx")

            sheets = df_w["SheetName"].unique().tolist()

            for s in sheets:
                df_s = df_w[df_w["SheetName"] == s]

                workbook_text.append(f"### WorkSheet: {s}")

                tables = df_s["TableName"].unique().tolist()

                for t in tables:
                    df_t = df_s[df_s["TableName"] == t]

                    workbook_text.append(f"**{t}**: ")
                    workbook_text.append(f"{df_t["Description"].unique()[0]}")
                    workbook_text.append("\n")
                    workbook_text.append(
                        f" - Veda Tag: `{df_t["VedaTag"].unique()[0]}`"
                    )
                    workbook_text.append("\n")
                    workbook_text.append(
                        f" - Data Location: `{df_t["DataLocation"].unique()[0]}`"
                    )
                    workbook_text.append("\n")

            out_path = Path(OUTPUT_LOCATION / filename)
            OUTPUT_LOCATION.mkdir(parents=True, exist_ok=True)
            workbook_text = "\n".join(workbook_text)
            out_path.write_text(workbook_text, encoding="utf-8")

    index_text = "\n".join(index_text)
    index_path = OUTPUT_LOCATION.parent / index_filename

    index_path.write_text(index_text, encoding="utf-8")


def main():
    """entry point"""

    OUTPUT_LOCATION.mkdir(parents=True, exist_ok=True)
    df = pd.read_csv(input_file)
    df = create_workbook_categories(df)
    generate_tag_markdown(df)


if __name__ == "__main__":
    main()
