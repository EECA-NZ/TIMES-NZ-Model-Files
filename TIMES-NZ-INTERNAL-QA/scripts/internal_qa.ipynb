{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internal QA sheets \n",
    "\n",
    "This script is designed to test the VD outputs of multiple scenarios \n",
    "\n",
    "Scenarios can be selected by version number and \"run\" name (eg kea, tui, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes \n",
    "\n",
    "We note that this will not consider the current post-processing system of \"raw\", \"main\", and \"clean\" data. \n",
    "\n",
    "This attempts to look at the actual model outputs while keeping handling as light as possible. \n",
    "\n",
    "Long term, the work done here might also be used for post-processing. Current post-processing has extra data handling which means it deviates from model outputs. This should be cleaned up. \n",
    "\n",
    "Separately, we want to create a big cool graph object for any given scenario run. This will be a separate project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concordance\n",
    "\n",
    "The concordance file (containing Att/Proc/Com metadata) is key to interpreting the TIMES-NZ specific outputs.\n",
    "\n",
    "The actual concordance data can be adjusted. It is found here:\n",
    "\n",
    "`TIMES-NZ-OUTPUT-PROCESSING/data/input/concordance/attribute_process_commodity_concordance.csv`. \n",
    "\n",
    "The interactive version can be browsed here: \n",
    "\n",
    "`TIMES-NZ-OUTPUT-PROCESSING/data/input/concordance/times_concordance_lookup.html`\n",
    "\n",
    "If the data is updated, the lookup file can be updated by navigating to `TIMES-NZ-OUTPUT-PROCESSING\\data\\input\\concordance` and running `create_lookup.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps: \n",
    "\n",
    "1) Define scenarios, versions \n",
    "2) Define methods for accessing relevant attributes/processes/fuels from the specified scenarios/versions\n",
    "3) Run check testing for any differences: \n",
    "    - new/missing attributes/processes/fuels \n",
    "    - within matching attributes/processes/fuels, where values are different\n",
    "    - output a report \n",
    "4) Output charts for visual assessments of differences\n",
    "    - Input differences (not VD files! This will need to wait for a better input data structure) \n",
    "    - Emissions\n",
    "      - Total\n",
    "      - Sector\n",
    "      - Fuel \n",
    "    - Supply\n",
    "      - to assess value of this? Not sure how interesting it is \n",
    "    - End use\n",
    "      - Sectors by fuel\n",
    "      - ESD (tech-agnostic)\n",
    "      - Technology uptake \n",
    "    - Generation\n",
    "      - Generation mix\n",
    "      - timeslices/peaking/peak cap\n",
    "      - Required build\n",
    "    - Prices\n",
    "      - (not input prices, these should be covered separately)\n",
    "      - Need to explore these better and ensure they make sense\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries \n",
    "import pandas as pd\n",
    "# import numpy as np\n",
    "import re\n",
    "import os \n",
    "from pathlib import Path\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario definitions \n",
    "\n",
    "# these should match the folder names in times_scenarios/ that we want to assess \n",
    "qa_runs = [\"tui-v2_1_2\", \"tui-v2_1_3\"]\n",
    "# we could do something fancy by saying like \"i want every version of tui\" or whatever,\n",
    "# but this is flexible to naming conventions changing in future \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data availability:\n",
      "`tui-v2_1_2` found :)\n",
      "`tui-v2_1_3` found :)\n"
     ]
    }
   ],
   "source": [
    "# checking directories and data \n",
    "\n",
    "# TIMES_LOCATION = os.getcwd()\n",
    "# go up one \n",
    "TIMES_LOCATION = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "# identify data location \n",
    "TIMES_OUTPUTS_RAW = os.path.join(TIMES_LOCATION, \"TIMES-NZ-GAMS\", \"times_scenarios\")\n",
    "\n",
    "# test that your scenarios exist \n",
    "\n",
    "# (to do: go down a bit and make sure the vd files exist)\n",
    "available_runs = os.listdir(TIMES_OUTPUTS_RAW)\n",
    "print(f\"Checking data availability:\")\n",
    "\n",
    "for run in qa_runs: \n",
    "    if run not in available_runs:\n",
    "        print(f\"Warning: `{run}` cannot be found in the current run data. Ensure you have processed veda correctly\")\n",
    "    else: \n",
    "        print(f\"`{run}` found :)\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data retrival functions \n",
    "\n",
    "\n",
    "def read_vd(filepath):\n",
    "    \"\"\"\n",
    "    Reads a VD file, using column names extracted from the file's\n",
    "    header with regex, skipping non-CSV formatted header lines.\n",
    "\n",
    "    :param filepath: Path to the VD file.\n",
    "    :param scen_label: Label for the 'scen' column for rows from this file.\n",
    "    \"\"\"\n",
    "    dimensions_pattern = re.compile(r\"\\*\\s*Dimensions-\")\n",
    "\n",
    "    # Determine the number of rows to skip and the column names\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        columns = None\n",
    "        skiprows = 0\n",
    "        for line in file:\n",
    "            if dimensions_pattern.search(line):\n",
    "                columns_line = line.split(\"- \")[1].strip()\n",
    "                columns = columns_line.split(\";\")\n",
    "                continue\n",
    "            if line.startswith('\"'):\n",
    "                break\n",
    "            skiprows += 1\n",
    "\n",
    "    # Read the CSV file with the determined column names and skiprows\n",
    "    vd_df = pd.read_csv(\n",
    "        filepath, skiprows=skiprows, names=columns, header=None, low_memory=False\n",
    "    )\n",
    "    return vd_df\n",
    "\n",
    "\n",
    "def get_attribute_df_single_run(attribute, run_name): \n",
    "    \"\"\"\n",
    "    Reads a TIMES vd file and returns a dataframe filtered to a specific attribute \n",
    "    \n",
    "    Parameters:\n",
    "    attribute (str): Attribute from a TIMES vd file to filter on \n",
    "    run_name (str): The name of the run this file is from. This must exist in the specified df\n",
    "    \n",
    "    Returns:\n",
    "    Dataframe - untouched vd output but on a specific attribute and with a run label \n",
    "    \"\"\"\n",
    "\n",
    "    filepath = os.path.join(TIMES_OUTPUTS_RAW, run_name, f\"{run_name}.vd\")\n",
    "    vd = read_vd(filepath)\n",
    "    vd = vd[vd[\"Attribute\"] == attribute]\n",
    "    vd[\"Scenario\"] = run_name\n",
    "    return vd\n",
    "    \n",
    "def add_concordance_to_vd(df):\n",
    "    \"\"\"\n",
    "    Takes a TIMES VD file with Attribute/Process/Commodity data, and adds the local concordance file to it \n",
    "    Hardcodes the concordance file location, which must exist\n",
    "    \n",
    "    Parameters:\n",
    "    df (str): the pandas dataframe we're adding the concordance to   \n",
    "\n",
    "    Returns:\n",
    "    a df with the new variables attached\n",
    "    \"\"\"\n",
    "\n",
    "    concordance_filepath = os.path.join(TIMES_LOCATION,\n",
    "                                        \"TIMES-NZ-OUTPUT-PROCESSING/data/input/concordance/\",\n",
    "                                        \"attribute_process_commodity_concordance.csv\")\n",
    "    \n",
    "    concordance_data = pd.read_csv(concordance_filepath)\n",
    "\n",
    "    df = df.merge(concordance_data,\n",
    "                  how = \"left\",\n",
    "                  on = [\"Attribute\", \"Process\", \"Commodity\"])\n",
    "    return df\n",
    "\n",
    "    \n",
    "\n",
    "def get_veda_data_no_concordance(attribute, runs = qa_runs):\n",
    "    \"\"\"\n",
    "    Combines previous functions to get the same attribute data for all relevant runs\n",
    "    then attach the concordance file for easy perusal. \n",
    "    \n",
    "    Parameters:\n",
    "    attribute (str): the VD attribute this pulls\n",
    "    runs (array): an array of run names stored as strings. Defaults to the `qa_runs` defined earlier \n",
    "\n",
    "    Returns:\n",
    "    a df \n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for run in runs: \n",
    "        vd_df = get_attribute_df_single_run(attribute, run)\n",
    "        df = pd.concat([df, vd_df])    \n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_veda_data(attribute, runs = qa_runs):\n",
    "    \n",
    "    df = get_veda_data_no_concordance(attribute, runs)\n",
    "    df = add_concordance_to_vd(df)\n",
    "\n",
    "    return df \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data \n",
    "fuel_use_df = get_veda_data(\"VAR_FIn\")\n",
    "output_df = get_veda_data(\"VAR_FOut\")\n",
    "cap_df = get_veda_data(\"VAR_Cap\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define aggregation categories\n",
    "# to this you can group by other stuff if needed like process/commopdity/sector or whatever but this will form the baseline? \n",
    "standard_group_categories = [\n",
    "    \"Attribute\",   \n",
    "    \"Period\",\n",
    "    \"Scenario\",\n",
    "    \"Unit\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing functions \n",
    "\n",
    "# for each attribute of interest (generalisable)\n",
    "# we want to take both the relevant tables and: \n",
    "\n",
    "    # a) run minus tests in both directions (covers all differences)\n",
    "    # b) identify all rows where everything matches except the data (ie the PV value). THis is some merge stuff probably? \n",
    "    # c) identify all rows where there are category differences agnostic to data. This is basically a minus test where we remove the PV before checking anything.\n",
    "\n",
    "\n",
    "# When doing structure minus testing, we have to be quite careful. TIMES will output 0s as implicit missing values. This means if a value is 0 in one run, and over 0 in another,\n",
    "# This will flag as a structure issue \n",
    "\n",
    "# So for the main minus testing we remove all time periods, time slices, and vintage categories, and just focus on the att/proc/comm combinations \n",
    "\n",
    "# An alternative approach would be to fill all the missings with explicit zeroes, but it would be best to do that in categories that align across both categories so we can identify data differences\n",
    "# within matching categories \n",
    "\n",
    "# pd.reset_option('display.max_rows')\n",
    "test_attribute = \"VAR_FIn\"\n",
    "\n",
    "\n",
    "def get_data_structure(attribute):\n",
    "    # the point of this is to return the dataframe with no numbers in it so we can test structure changes \n",
    "    # while we are here we are going \n",
    "    df = get_veda_data_no_concordance(attribute)\n",
    "    # remove PV and ensure grain holds \n",
    "\n",
    "\n",
    "    current_count = len(df)\n",
    "    \n",
    "    df_no_pv = df.drop(\"PV\", axis = 1).drop_duplicates()\n",
    "    new_count = len(df_no_pv) \n",
    "\n",
    "    if current_count != new_count:\n",
    "        print(f\"Error: '{attribute}' data has {current_count} rows\")\n",
    "        print(f\"However, it has {new_count} rows after removing PV and collapsing\")\n",
    "        print(f\"Mismatched counts imply rows are not uniquely defined in Veda output!! Help!!\")\n",
    "\n",
    "    return df_no_pv\n",
    "\n",
    "def remove_time_periods(df):\n",
    "\n",
    "    df = df.drop(\"Period\", axis = 1).drop_duplicates()\n",
    "    df = df.drop(\"TimeSlice\", axis = 1).drop_duplicates()\n",
    "    df = df.drop(\"Vintage\", axis = 1).drop_duplicates()\n",
    "\n",
    "    return df\n",
    "\n",
    "def minus_test_structure(attribute, run_a, run_b, max_rows = 100): \n",
    "\n",
    "    df = get_data_structure(attribute) \n",
    "    # drop times to remove noise \n",
    "    df = remove_time_periods(df) \n",
    "\n",
    "    # get separate tables     \n",
    "    df_a = df[df[\"Scenario\"] == run_a].drop(\"Scenario\", axis = 1)\n",
    "    df_b = df[df[\"Scenario\"] == run_b].drop(\"Scenario\", axis = 1)  \n",
    "\n",
    "    # minus \n",
    "    a_minus_b = (    \n",
    "        df_a\n",
    "        .merge(df_b, how='left', indicator=True)\n",
    "        .query('_merge == \"left_only\"')\n",
    "        .drop('_merge', axis=1)\n",
    "        )\n",
    "    \n",
    "    # assess result \n",
    "    if len(a_minus_b) > 0: \n",
    "       print(f\"The following structures are defined in '{run_a}' but not '{run_b}'\")\n",
    "       a_minus_b = add_concordance_to_vd(a_minus_b)\n",
    "       pd.set_option('display.max_rows', max_rows)\n",
    "       return a_minus_b\n",
    "    else: \n",
    "        print(f\"All CAP, ATT, and PROC combinations in '{run_b}' are also found in '{run_a}'\")    \n",
    "\n",
    "    # a - b \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minus testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following structures are defined in 'tui-v2_1_2' but not 'tui-v2_1_3'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Commodity</th>\n",
       "      <th>Process</th>\n",
       "      <th>Region</th>\n",
       "      <th>UserConstraint</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Subsector</th>\n",
       "      <th>Technology</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Enduse</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>FuelGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VAR_FIn</td>\n",
       "      <td>COA</td>\n",
       "      <td>IIS-FDSTCK-COA-_</td>\n",
       "      <td>NI</td>\n",
       "      <td>-</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Iron/Steel</td>\n",
       "      <td>Feedstock</td>\n",
       "      <td>Coal</td>\n",
       "      <td>Feedstock</td>\n",
       "      <td>PJ</td>\n",
       "      <td>Feedstock</td>\n",
       "      <td>Fossil Fuels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VAR_FIn</td>\n",
       "      <td>NGA</td>\n",
       "      <td>MTHOL-FDSTCK-NGA-FDSTCK</td>\n",
       "      <td>NI</td>\n",
       "      <td>-</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Methanol</td>\n",
       "      <td>Feedstock</td>\n",
       "      <td>Natural Gas</td>\n",
       "      <td>Feedstock</td>\n",
       "      <td>PJ</td>\n",
       "      <td>Feedstock</td>\n",
       "      <td>Fossil Fuels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VAR_FIn</td>\n",
       "      <td>INDNGA</td>\n",
       "      <td>MTHOL-PH_REFRM-NGA-REFRM</td>\n",
       "      <td>NI</td>\n",
       "      <td>-</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Methanol</td>\n",
       "      <td>Reformer</td>\n",
       "      <td>Natural Gas</td>\n",
       "      <td>Process Heat Reformer</td>\n",
       "      <td>PJ</td>\n",
       "      <td>Fuel Consumption</td>\n",
       "      <td>Fossil Fuels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Attribute Commodity                   Process Region UserConstraint  \\\n",
       "0   VAR_FIn       COA          IIS-FDSTCK-COA-_     NI              -   \n",
       "1   VAR_FIn       NGA   MTHOL-FDSTCK-NGA-FDSTCK     NI              -   \n",
       "2   VAR_FIn    INDNGA  MTHOL-PH_REFRM-NGA-REFRM     NI              -   \n",
       "\n",
       "     Sector   Subsector Technology         Fuel                 Enduse Unit  \\\n",
       "0  Industry  Iron/Steel  Feedstock         Coal              Feedstock   PJ   \n",
       "1  Industry    Methanol  Feedstock  Natural Gas              Feedstock   PJ   \n",
       "2  Industry    Methanol   Reformer  Natural Gas  Process Heat Reformer   PJ   \n",
       "\n",
       "         Parameters     FuelGroup  \n",
       "0         Feedstock  Fossil Fuels  \n",
       "1         Feedstock  Fossil Fuels  \n",
       "2  Fuel Consumption  Fossil Fuels  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VAR_FIN A MINUS B\n",
    "minus_test_structure(\"VAR_FIn\", qa_runs[0], qa_runs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following structures are defined in 'tui-v2_1_3' but not 'tui-v2_1_2'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Commodity</th>\n",
       "      <th>Process</th>\n",
       "      <th>Region</th>\n",
       "      <th>UserConstraint</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Subsector</th>\n",
       "      <th>Technology</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Enduse</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>FuelGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VAR_FIn</td>\n",
       "      <td>INDFOL</td>\n",
       "      <td>OTH-FOL-FOL-Tech15</td>\n",
       "      <td>NI</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VAR_FIn</td>\n",
       "      <td>COA</td>\n",
       "      <td>TU_COA_SI_NI_01</td>\n",
       "      <td>SI</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fossil Fuels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VAR_FIn</td>\n",
       "      <td>INDFOL</td>\n",
       "      <td>OTH-FOL-FOL-Tech15</td>\n",
       "      <td>SI</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VAR_FIn</td>\n",
       "      <td>INDELC</td>\n",
       "      <td>PLPPPR-AIR-ELC-CMPR15</td>\n",
       "      <td>SI</td>\n",
       "      <td>-</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Pulp and Paper Manufacturing</td>\n",
       "      <td>Compressor</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Compressed Air</td>\n",
       "      <td>PJ</td>\n",
       "      <td>Fuel Consumption</td>\n",
       "      <td>Electricity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Attribute Commodity                Process Region UserConstraint    Sector  \\\n",
       "0   VAR_FIn    INDFOL     OTH-FOL-FOL-Tech15     NI              -       NaN   \n",
       "1   VAR_FIn       COA        TU_COA_SI_NI_01     SI              -       NaN   \n",
       "2   VAR_FIn    INDFOL     OTH-FOL-FOL-Tech15     SI              -       NaN   \n",
       "3   VAR_FIn    INDELC  PLPPPR-AIR-ELC-CMPR15     SI              -  Industry   \n",
       "\n",
       "                      Subsector  Technology         Fuel          Enduse Unit  \\\n",
       "0                           NaN         NaN          NaN             NaN  NaN   \n",
       "1                           NaN         NaN         Coal             NaN   PJ   \n",
       "2                           NaN         NaN          NaN             NaN  NaN   \n",
       "3  Pulp and Paper Manufacturing  Compressor  Electricity  Compressed Air   PJ   \n",
       "\n",
       "         Parameters     FuelGroup  \n",
       "0               NaN           NaN  \n",
       "1               NaN  Fossil Fuels  \n",
       "2               NaN           NaN  \n",
       "3  Fuel Consumption   Electricity  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VAR_FIN B MINUS A\n",
    "minus_test_structure(\"VAR_FIn\", qa_runs[1], qa_runs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following structures are defined in 'tui-v2_1_2' but not 'tui-v2_1_3'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Commodity</th>\n",
       "      <th>Process</th>\n",
       "      <th>Region</th>\n",
       "      <th>UserConstraint</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Subsector</th>\n",
       "      <th>Technology</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Enduse</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>FuelGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VAR_FOut</td>\n",
       "      <td>IIS-FDSTCK</td>\n",
       "      <td>IIS-FDSTCK-COA-_</td>\n",
       "      <td>NI</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VAR_FOut</td>\n",
       "      <td>MTHOL-FDSTCK</td>\n",
       "      <td>MTHOL-FDSTCK-NGA-FDSTCK</td>\n",
       "      <td>NI</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VAR_FOut</td>\n",
       "      <td>INDCO2</td>\n",
       "      <td>MTHOL-PH_REFRM-NGA-REFRM</td>\n",
       "      <td>NI</td>\n",
       "      <td>-</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Methanol</td>\n",
       "      <td>Reformer</td>\n",
       "      <td>Natural Gas</td>\n",
       "      <td>Process Heat Reformer</td>\n",
       "      <td>kt CO2</td>\n",
       "      <td>Emissions</td>\n",
       "      <td>Fossil Fuels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VAR_FOut</td>\n",
       "      <td>MTHOL-PH_REFRM</td>\n",
       "      <td>MTHOL-PH_REFRM-NGA-REFRM</td>\n",
       "      <td>NI</td>\n",
       "      <td>-</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Methanol</td>\n",
       "      <td>Reformer</td>\n",
       "      <td>Natural Gas</td>\n",
       "      <td>Process Heat Reformer</td>\n",
       "      <td>PJ</td>\n",
       "      <td>End Use Demand</td>\n",
       "      <td>Fossil Fuels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Attribute       Commodity                   Process Region UserConstraint  \\\n",
       "0  VAR_FOut      IIS-FDSTCK          IIS-FDSTCK-COA-_     NI              -   \n",
       "1  VAR_FOut    MTHOL-FDSTCK   MTHOL-FDSTCK-NGA-FDSTCK     NI              -   \n",
       "2  VAR_FOut          INDCO2  MTHOL-PH_REFRM-NGA-REFRM     NI              -   \n",
       "3  VAR_FOut  MTHOL-PH_REFRM  MTHOL-PH_REFRM-NGA-REFRM     NI              -   \n",
       "\n",
       "     Sector Subsector Technology         Fuel                 Enduse    Unit  \\\n",
       "0       NaN       NaN        NaN          NaN                    NaN     NaN   \n",
       "1       NaN       NaN        NaN          NaN                    NaN     NaN   \n",
       "2  Industry  Methanol   Reformer  Natural Gas  Process Heat Reformer  kt CO2   \n",
       "3  Industry  Methanol   Reformer  Natural Gas  Process Heat Reformer      PJ   \n",
       "\n",
       "       Parameters     FuelGroup  \n",
       "0             NaN           NaN  \n",
       "1             NaN           NaN  \n",
       "2       Emissions  Fossil Fuels  \n",
       "3  End Use Demand  Fossil Fuels  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VAR_FOUT A MINUS B\n",
    "minus_test_structure(\"VAR_FOut\", qa_runs[0], qa_runs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following structures are defined in 'tui-v2_1_3' but not 'tui-v2_1_2'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Commodity</th>\n",
       "      <th>Process</th>\n",
       "      <th>Region</th>\n",
       "      <th>UserConstraint</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Subsector</th>\n",
       "      <th>Technology</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Enduse</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>FuelGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VAR_FOut</td>\n",
       "      <td>COA</td>\n",
       "      <td>TU_COA_SI_NI_01</td>\n",
       "      <td>NI</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fossil Fuels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VAR_FOut</td>\n",
       "      <td>INDCO2</td>\n",
       "      <td>OTH-FOL-FOL-Tech15</td>\n",
       "      <td>NI</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VAR_FOut</td>\n",
       "      <td>OTH-FOL</td>\n",
       "      <td>OTH-FOL-FOL-Tech15</td>\n",
       "      <td>NI</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VAR_FOut</td>\n",
       "      <td>INDCO2</td>\n",
       "      <td>OTH-FOL-FOL-Tech15</td>\n",
       "      <td>SI</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VAR_FOut</td>\n",
       "      <td>OTH-FOL</td>\n",
       "      <td>OTH-FOL-FOL-Tech15</td>\n",
       "      <td>SI</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VAR_FOut</td>\n",
       "      <td>PLPPPR-AIR</td>\n",
       "      <td>PLPPPR-AIR-ELC-CMPR15</td>\n",
       "      <td>SI</td>\n",
       "      <td>-</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Pulp and Paper Manufacturing</td>\n",
       "      <td>Compressor</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Compressed Air</td>\n",
       "      <td>PJ</td>\n",
       "      <td>End Use Demand</td>\n",
       "      <td>Electricity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Attribute   Commodity                Process Region UserConstraint  \\\n",
       "0  VAR_FOut         COA        TU_COA_SI_NI_01     NI              -   \n",
       "1  VAR_FOut      INDCO2     OTH-FOL-FOL-Tech15     NI              -   \n",
       "2  VAR_FOut     OTH-FOL     OTH-FOL-FOL-Tech15     NI              -   \n",
       "3  VAR_FOut      INDCO2     OTH-FOL-FOL-Tech15     SI              -   \n",
       "4  VAR_FOut     OTH-FOL     OTH-FOL-FOL-Tech15     SI              -   \n",
       "5  VAR_FOut  PLPPPR-AIR  PLPPPR-AIR-ELC-CMPR15     SI              -   \n",
       "\n",
       "     Sector                     Subsector  Technology         Fuel  \\\n",
       "0       NaN                           NaN         NaN         Coal   \n",
       "1       NaN                           NaN         NaN          NaN   \n",
       "2       NaN                           NaN         NaN          NaN   \n",
       "3       NaN                           NaN         NaN          NaN   \n",
       "4       NaN                           NaN         NaN          NaN   \n",
       "5  Industry  Pulp and Paper Manufacturing  Compressor  Electricity   \n",
       "\n",
       "           Enduse Unit      Parameters     FuelGroup  \n",
       "0             NaN   PJ             NaN  Fossil Fuels  \n",
       "1             NaN  NaN             NaN           NaN  \n",
       "2             NaN  NaN             NaN           NaN  \n",
       "3             NaN  NaN             NaN           NaN  \n",
       "4             NaN  NaN             NaN           NaN  \n",
       "5  Compressed Air   PJ  End Use Demand   Electricity  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VAR_FOUT B MINUS A\n",
    "minus_test_structure(\"VAR_FOut\", qa_runs[1], qa_runs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minus_test_df(df_a, df_b):\n",
    "\n",
    "    a_minus_b = (    \n",
    "        df_a\n",
    "        .merge(df_b, how='left', indicator=True)\n",
    "        .query('_merge == \"left_only\"')\n",
    "        .drop('_merge', axis=1)\n",
    "        )\n",
    "    return(a_minus_b)\n",
    "\n",
    "def check_minus_test(df, run_a, run_b, variable, display = True):    \n",
    "    \n",
    "    df_a = df[df[\"Scenario\"] == run_a].drop(\"Scenario\", axis = 1)\n",
    "    df_b = df[df[\"Scenario\"] == run_b].drop(\"Scenario\", axis = 1)\n",
    "\n",
    "    a_minus_b = get_minus_test_df(df_a,df_b)\n",
    "\n",
    "    if len(a_minus_b) == 0:\n",
    "        print(f\"All instances of '{variable}' in '{run_a}' are also in '{run_b}'\")\n",
    "\n",
    "    else: \n",
    "        failed_categories = a_minus_b[variable]      \n",
    "\n",
    "        if display:     \n",
    "            print(f\"The following instances of '{variable}' in '{run_a}' are not in `{run_b}`:\")\n",
    "            for category in failed_categories:\n",
    "                print(f\" - {category}\")\n",
    "\n",
    "        else: \n",
    "            return failed_categories\n",
    "        \n",
    "\n",
    "def check_category_mismatch(attribute, variable, run_a, run_b):    \n",
    "\n",
    "    print(f\"{attribute}: checking {variable} matches\")\n",
    "    # get the atty data \n",
    "    df = get_veda_data_no_concordance(attribute)\n",
    "    # identify unique values of variable\n",
    "    df = df[[variable, \"Scenario\"]].drop_duplicates()\n",
    "\n",
    "    check_minus_test(df, run_a, run_b, variable)\n",
    "    check_minus_test(df, run_b, run_a, variable)\n",
    "    print()\n",
    "    \n",
    "def check_all_category_mismatches(run_a, run_b):\n",
    "\n",
    "    attributes_to_check = [\"VAR_FIn\", \"VAR_FOut\", \"VAR_CAP\"]\n",
    "    variables_to_check = [\"Process\", \"Commodity\"]\n",
    "\n",
    "\n",
    "    for attribute in attributes_to_check:\n",
    "        for variable in variables_to_check:\n",
    "            check_category_mismatch(attribute, variable, run_a, run_b)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_a = qa_runs[0]\n",
    "run_b = qa_runs[1]\n",
    "\n",
    "check_all_category_mismatches(run_a, run_b)\n",
    "\n",
    "\n",
    "\n",
    "#check_missing_category(\"VAR_FIn\", \"Commodity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECK DATA CHANGES \n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "METHOD\n",
    "\n",
    "\n",
    "We want to test any data changes given the grain of attribute, process, commodity, period, and region.\n",
    "Put another way, we want to hold those things constant between tables (so trim both to match) and then assess which ones have had values change\n",
    "\n",
    "We will assess only if numbers change within these grains \n",
    "We won't capture if numbers changed because the structures of these changed (eg a process was renamed),\n",
    "because that testing is done elsewhere.\n",
    "\n",
    "This means the aggregated output of these might be the same at a Period level!\n",
    "However we will capture if eg; some demand has shifted in its timeslice.\n",
    "It is better to assess that here, rather than chalking it up to a category change in our category change testing.\n",
    "Timeslice or vintage changes can be a bit overwhelming/noisy\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "run_a = qa_runs[0]\n",
    "run_b = qa_runs[1]\n",
    "\n",
    "constant_variables = [\"Attribute\", \"Commodity\", \"Process\", \"Period\", \"Region\"]\n",
    "\n",
    "\n",
    "# get all unique combinations for each scenario\n",
    "\n",
    "only_variables = (output_df.drop_duplicates(subset = constant_variables + [\"Scenario\"]))     \n",
    "\n",
    "variables_a = only_variables[only_variables[\"Scenario\"] == run_a].drop(\"Scenario\", axis = 1)\n",
    "variables_b = only_variables[only_variables[\"Scenario\"] == run_b].drop(\"Scenario\", axis = 1)\n",
    "\n",
    "matching_variables = pd.merge(\n",
    "    variables_a, variables_b, \n",
    "    on = constant_variables,\n",
    "    suffixes = (\"_a\", \"_b\")\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# first, aggregate the main table by the constant variables and scenario \n",
    "\n",
    "agg_table = (output_df\n",
    "             .groupby(constant_variables + [\"Scenario\"])\n",
    "             .sum(\"PV\").reset_index()\n",
    ")\n",
    "\n",
    "# retain all other variables in pivot\n",
    "index_cols = [col for col in agg_table.columns if col not in [\"PV\", \"Scenario\"]]\n",
    "\n",
    "delta_test = agg_table.pivot(    \n",
    "    index = index_cols,\n",
    "    columns = \"Scenario\",\n",
    "    values = \"PV\"\n",
    ").fillna(0).reset_index()\n",
    "\n",
    "\n",
    "delta_test[\"Delta\"] = delta_test[run_a] - delta_test[run_b]\n",
    "\n",
    "# tolerance within 0.1% change\n",
    "# i thought i would need to mess around with the way it handles 0s but it seems to work fine \n",
    "delta_test[\"Delta_Proc\"] = delta_test[run_b] / delta_test[run_a] - 1\n",
    "delta_test =  delta_test[(abs(delta_test[\"Delta_Proc\"]) > 0.001 )] \n",
    "\n",
    "\n",
    "# add concordance back \n",
    "delta_test = add_concordance_to_vd(delta_test)\n",
    "\n",
    "#delta_test = delta_test.groupby([\"Attribute\", \"Commodity\", \"Process\"]).size().reset_index(name = \"diff_count\")\n",
    "\n",
    "#$delta_test = add_concordance_to_vd(delta_test)\n",
    "\n",
    "pd.set_option('display.max_rows', 10              )\n",
    "\n",
    "\n",
    "changed_grain = delta_test.groupby([\"Attribute\", \"Process\", \"Commodity\"]).size().reset_index(name = \"Count\").drop(\"Count\", axis = 1 )\n",
    "\n",
    "\n",
    "delta_data = output_df.merge(changed_grain)\n",
    "\n",
    "df = delta_data\n",
    "\n",
    "sector_options = delta_data[\"Sector\"].unique()\n",
    "parameter_options = delta_data[\"Parameters\"].unique()\n",
    "\n",
    "\n",
    "sector_options\n",
    "\n",
    "df[\"Parameters\"].unique()\n",
    "df.columns\n",
    "\n",
    "# Replace NaN with \"Missing\" in those columns\n",
    "string_columns = df.select_dtypes(include=['object']).columns\n",
    "string_columns = [col for col in string_columns if col != 'PV']\n",
    "df[string_columns] = df[string_columns].fillna('Missing')\n",
    "\n",
    "sector_options = df[\"Sector\"].unique().tolist()\n",
    "parameter_options = df[\"Parameters\"].unique().tolist()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output, State\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "\n",
    "# Define the drill-down hierarchy\n",
    "HIERARCHY = ['Fuel', 'Subsector', 'Technology', 'TimeSlice']\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Initialize the layout with a store component\n",
    "app.layout = html.Div([\n",
    "    # Store for keeping track of the current view state\n",
    "    dcc.Store(id='view-state', data={\n",
    "        'level': 0,  # Index into HIERARCHY\n",
    "        'selections': {}  # Will store {field: value} pairs as we drill down\n",
    "    }),\n",
    "    \n",
    "    html.H1('Energy System Analysis Dashboard', \n",
    "            style={'textAlign': 'center', 'marginBottom': '20px'}),\n",
    "            \n",
    "    # Header area for current filters\n",
    "    html.Div(id='current-filters', style={'marginBottom': '20px', 'padding': '10px', 'backgroundColor': '#f8f9fa'}),\n",
    "    \n",
    "    # Current view title\n",
    "    html.H2(id='view-title', style={'textAlign': 'center', 'marginBottom': '20px'}),\n",
    "    \n",
    "    # Container for filters and navigation\n",
    "    html.Div([\n",
    "        # Parameter dropdown\n",
    "        html.Div([\n",
    "            html.Label('Select Parameter:'),\n",
    "            dcc.Dropdown(\n",
    "                id='parameter-dropdown',\n",
    "                options=[{'label': param, 'value': param} for param in parameter_options],\n",
    "                value=parameter_options[0]\n",
    "            )\n",
    "        ], id='param-dropdown-container', style={'width': '30%', 'display': 'inline-block'}),\n",
    "        \n",
    "        # Back button (initially hidden)\n",
    "        html.Button(\n",
    "            'Back',\n",
    "            id='back-button',\n",
    "            style={'display': 'none', 'marginLeft': '20px'},\n",
    "        )\n",
    "    ], style={'marginBottom': '20px'}),\n",
    "    \n",
    "    # Main graph\n",
    "    html.Div([\n",
    "        dcc.Graph(id='faceted-chart', style={'height': '800px'}),\n",
    "    ])\n",
    "])\n",
    "\n",
    "# Callback to handle clicks and view state\n",
    "@app.callback(\n",
    "    [Output('view-state', 'data'),\n",
    "     Output('back-button', 'style'),\n",
    "     Output('param-dropdown-container', 'style'),\n",
    "     Output('current-filters', 'children'),\n",
    "     Output('view-title', 'children')],\n",
    "    [Input('faceted-chart', 'clickAnnotationData'),\n",
    "     Input('back-button', 'n_clicks')],\n",
    "    [State('view-state', 'data'),\n",
    "     State('parameter-dropdown', 'value')]\n",
    ")\n",
    "def update_view_state(annotation_click, back_clicks, current_state, selected_parameter):\n",
    "    ctx = dash.callback_context\n",
    "    if not ctx.triggered:\n",
    "        # Generate initial filter display\n",
    "        filter_display = [html.P(f\"Parameter: {selected_parameter}\", style={'fontWeight': 'bold', 'marginBottom': '5px'})]\n",
    "        view_title = HIERARCHY[current_state['level']] + 's'\n",
    "    \n",
    "        return current_state, {'display': 'none'}, {'width': '30%', 'display': 'inline-block'}, filter_display, view_title\n",
    "    \n",
    "    trigger = ctx.triggered[0]['prop_id'].split('.')[0]\n",
    "    \n",
    "    if trigger == 'back-button':\n",
    "        # Go back one level\n",
    "        new_level = max(0, current_state['level'] - 1)\n",
    "        new_selections = dict(list(current_state['selections'].items())[:new_level])\n",
    "        \n",
    "        # Show dropdown only at top level\n",
    "        dropdown_style = {'width': '30%', 'display': 'inline-block'} if new_level == 0 else {'display': 'none'}\n",
    "        # Show back button except at top level\n",
    "        button_style = {'display': 'none'} if new_level == 0 else {'display': 'inline-block', 'marginLeft': '20px'}\n",
    "        \n",
    "        # Generate filter display\n",
    "        filter_display = [html.P(f\"Parameter: {selected_parameter}\", style={'fontWeight': 'bold', 'marginBottom': '5px'})]\n",
    "        for field in HIERARCHY[:new_level]:\n",
    "            if field in new_selections:\n",
    "                filter_display.append(html.P(f\"{field}: {new_selections[field]}\", \n",
    "                                          style={'fontWeight': 'bold', 'marginBottom': '5px'}))\n",
    "        \n",
    "        # Generate view title\n",
    "        view_title = 'Select ' + HIERARCHY[new_level] # could also pluralise but \"technologies\" is annoying\n",
    "        \n",
    "        return {\n",
    "            'level': new_level,\n",
    "            'selections': new_selections\n",
    "        }, button_style, dropdown_style, filter_display, view_title\n",
    "    \n",
    "    if trigger == 'faceted-chart' and annotation_click:\n",
    "        # Clean the selected value (remove arrows and whitespace)\n",
    "        selected_value = annotation_click['annotation']['text'].replace('â¯†', '').strip()\n",
    "        \n",
    "        # Get the current field we're looking at\n",
    "        current_field = HIERARCHY[current_state['level']]\n",
    "        \n",
    "        # Update selections with the new value\n",
    "        new_selections = dict(current_state['selections'])\n",
    "        new_selections[current_field] = selected_value\n",
    "        \n",
    "        # Move to next level if not at end\n",
    "        new_level = min(len(HIERARCHY) - 1, current_state['level'] + 1)\n",
    "        \n",
    "        # Generate filter display\n",
    "        filter_display = [html.P(f\"Parameter: {selected_parameter}\", style={'fontWeight': 'bold', 'marginBottom': '5px'})]\n",
    "        for field in HIERARCHY[:new_level + 1]:\n",
    "            if field in new_selections:\n",
    "                filter_display.append(html.P(f\"{field}: {new_selections[field]}\", \n",
    "                                          style={'fontWeight': 'bold', 'marginBottom': '5px'}))\n",
    "        \n",
    "        # Generate view title\n",
    "        view_title = HIERARCHY[new_level] + 's'  # Pluralize\n",
    "        \n",
    "        return {\n",
    "            'level': new_level,\n",
    "            'selections': new_selections\n",
    "        }, {'display': 'inline-block', 'marginLeft': '20px'}, {'display': 'none'}, filter_display, view_title\n",
    "    \n",
    "    return current_state, {'display': 'none'}, {'width': '30%', 'display': 'inline-block'}\n",
    "\n",
    "\n",
    "# Callback to update the graph\n",
    "@app.callback(\n",
    "    Output('faceted-chart', 'figure'),\n",
    "    [Input('parameter-dropdown', 'value'),\n",
    "     Input('view-state', 'data')]\n",
    ")\n",
    "def update_graph(selected_parameter, view_state):\n",
    "    # Start with parameter filter\n",
    "    filtered_df = df[df['Parameters'] == selected_parameter]\n",
    "    \n",
    "    # Apply all accumulated filters\n",
    "    for field, value in view_state['selections'].items():\n",
    "        filtered_df = filtered_df[filtered_df[field] == value]\n",
    "    \n",
    "    # Get current faceting field\n",
    "    facet_column = HIERARCHY[view_state['level']]\n",
    "    \n",
    "    # Aggregate data\n",
    "    agg_df = filtered_df.groupby(['Period', facet_column, 'Scenario'])['PV'].sum().reset_index()\n",
    "    \n",
    "    # Get available facet values\n",
    "    facet_values = sorted(agg_df[facet_column].unique())\n",
    "    \n",
    "    # Handle empty dataset case\n",
    "    if len(facet_values) == 0:\n",
    "        fig = go.Figure()\n",
    "        fig.add_annotation(\n",
    "            text='No data available for the selected filters',\n",
    "            xref=\"paper\",\n",
    "            yref=\"paper\",\n",
    "            x=0.5,\n",
    "            y=0.5,\n",
    "            showarrow=False,\n",
    "            font=dict(size=14)\n",
    "        )\n",
    "        return fig\n",
    "\n",
    "    # Calculate number of rows and columns for subplots\n",
    "    n_facets = len(facet_values)\n",
    "    n_cols = min(6, max(1, n_facets))\n",
    "    n_rows = max(1, (n_facets + n_cols - 1) // n_cols)\n",
    "    \n",
    "    # Create subplot figure\n",
    "    fig = make_subplots(\n",
    "        rows=n_rows, cols=n_cols\n",
    "        #vertical_spacing=0.3,\n",
    "        #horizontal_spacing=0.05\n",
    "    )\n",
    "    \n",
    "    # Color mapping for scenarios\n",
    "    color_map = {run_a: 'red', run_b: 'blue'}\n",
    "    \n",
    "    # Add traces for each facet value\n",
    "    for idx, facet_value in enumerate(facet_values):\n",
    "        row = idx // n_cols + 1\n",
    "        col = idx % n_cols + 1\n",
    "        \n",
    "        facet_data = agg_df[agg_df[facet_column] == facet_value]\n",
    "        \n",
    "        # Add title annotation with different styling based on whether we can drill deeper\n",
    "        can_drill_deeper = view_state['level'] < len(HIERARCHY) - 1\n",
    "        if can_drill_deeper:\n",
    "            fig.add_annotation(\n",
    "                text='â¯† ' + facet_value + ' â¯†',\n",
    "                xref=\"x domain\",\n",
    "                yref=\"y domain\",\n",
    "                x=0.5,\n",
    "                y=1.1,\n",
    "                showarrow=False,\n",
    "                xanchor=\"center\",\n",
    "                yanchor=\"bottom\",\n",
    "                row=row,\n",
    "                col=col,\n",
    "                font=dict(size=12, color='#0066cc'),\n",
    "                bgcolor='rgba(240, 248, 255, 0.8)',\n",
    "                bordercolor='#0066cc',\n",
    "                borderwidth=1,\n",
    "                borderpad=4,\n",
    "                hovertext='Click to drill down',\n",
    "            )\n",
    "        else:\n",
    "            fig.add_annotation(\n",
    "                text=facet_value,\n",
    "                xref=\"x domain\",\n",
    "                yref=\"y domain\",\n",
    "                x=0.5,\n",
    "                y=1.1,\n",
    "                showarrow=False,\n",
    "                xanchor=\"center\",\n",
    "                yanchor=\"bottom\",\n",
    "                row=row,\n",
    "                col=col,\n",
    "                font=dict(size=12)\n",
    "            )\n",
    "        \n",
    "        for scenario in [run_a, run_b]:\n",
    "            scenario_data = facet_data[facet_data['Scenario'] == scenario]\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    x=scenario_data['Period'],\n",
    "                    y=scenario_data['PV'],\n",
    "                    name=scenario,\n",
    "                    marker_color=color_map[scenario],\n",
    "                    showlegend=True if idx == 0 else False,\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "    \n",
    "    # Simple title for the graph\n",
    "    title_text = f\"{facet_column} Comparison\"\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=300 * n_rows,\n",
    "        title_text=title_text,\n",
    "        barmode='group',\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"right\",\n",
    "            x=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Update axes labels\n",
    "    fig.update_xaxes(title_text=\"Period\")\n",
    "    fig.update_yaxes(title_text=\"Value\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute tests\n",
    "\n",
    "\n",
    "# first, can only be done with 2 input runs. \n",
    "\n",
    "# we also define which attributes we want to check:\n",
    "\n",
    "attributes_to_test = [\"VAR_FIn\", \"VAR_FOut\", \"VAR_Cap\"]\n",
    "\n",
    "if len(qa_runs) == 2:\n",
    "    print(\"Running automated difference testing\")\n",
    "else:\n",
    "    if len(qa_runs < 2): \n",
    "        wrong_runs_message = \"Warning: you have selected less than 2 runs.\"\n",
    "    if len(qa_runs > 2):\n",
    "        wrong_runs_message = \"Warning: you have selected more than 2 runs.\"\n",
    "    print(f\"{wrong_runs_message} Skipping automated testing\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMISSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL EMISSIONS \n",
    "totcap_data = output_df[output_df[\"Commodity\"] == \"TOTCO2\"]\n",
    "print(f\"Warning: making manual adjustments to units for TOTCO2. This should really be done in the concordance file if these are needed\")\n",
    "totcap_data.loc[:,\"Unit\"] = \"ktco2e\"\n",
    "\n",
    "# all emissions by scenario, year \n",
    "totcap_data = (\n",
    "    totcap_data \n",
    "    .groupby(standard_group_categories)\n",
    "    .sum([\"PV\"])\n",
    "    .reset_index()\n",
    ")\n",
    "# convert to MT \n",
    "totcap_data[\"PV\"] /= 1000\n",
    "totcap_data[\"Unit\"] = \"MT CO2\"\n",
    "\n",
    "sns.relplot(\n",
    "    data = totcap_data, \n",
    "    x = \"Period\", y = \"PV\", hue = \"Scenario\",\n",
    "    kind = \"line\",\n",
    ")\n",
    "plt.title(\"Total Emissions\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Mt CO2\") # not co2e?? \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSITIVE EMISSIONS\n",
    "\n",
    "totcap_data = output_df[output_df[\"Commodity\"] == \"TOTCO2\"]\n",
    "print(f\"Warning: making manual adjustments to units for TOTCO2. This should really be done in the concordance file if these are needed\")\n",
    "totcap_data.loc[:,\"Unit\"] = \"ktco2e\"\n",
    "\n",
    "totcap_data_positive = totcap_data[totcap_data[\"PV\"] > 0]\n",
    "\n",
    "# all emissions by scenario, year \n",
    "totcap_data_positive = (\n",
    "    totcap_data_positive \n",
    "    .groupby(standard_group_categories)\n",
    "    .sum([\"PV\"])\n",
    "    .reset_index()\n",
    ")\n",
    "# convert to MT \n",
    "totcap_data_positive[\"PV\"] /= 1000\n",
    "totcap_data_positive[\"Unit\"] = \"MT CO2\"\n",
    "\n",
    "sns.relplot(\n",
    "    data = totcap_data_positive, \n",
    "    x = \"Period\", y = \"PV\", hue = \"Scenario\",\n",
    "    kind = \"line\"    \n",
    ")\n",
    "plt.title(\"Positive Emissions\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Mt CO2\") # not co2e?? \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEGATIVE EMISSIONS\n",
    "\n",
    "totcap_data = output_df[output_df[\"Commodity\"] == \"TOTCO2\"]\n",
    "print(f\"Warning: making manual adjustments to units for TOTCO2. This should really be done in the concordance file if these are needed\")\n",
    "totcap_data.loc[:,\"Unit\"] = \"ktco2e\"\n",
    "\n",
    "totcap_data_negative = totcap_data[totcap_data[\"PV\"] < 0]\n",
    "\n",
    "# all emissions by scenario, year \n",
    "totcap_data_negative = (\n",
    "    totcap_data_negative \n",
    "    .groupby(standard_group_categories)\n",
    "    .sum([\"PV\"])\n",
    "    .reset_index()\n",
    ")\n",
    "# convert to MT \n",
    "totcap_data_negative[\"PV\"] /= 1000\n",
    "totcap_data_negative[\"Unit\"] = \"MT CO2\"\n",
    "\n",
    "sns.relplot(\n",
    "    data = totcap_data_negative, \n",
    "    x = \"Period\", y = \"PV\", hue = \"Scenario\",\n",
    "    kind = \"line\"    \n",
    ")\n",
    "plt.title(\"NEGATIVE Emissions\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Mt CO2\") # not co2e?? \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMISSIONS BY SECTOR\n",
    "\n",
    "\n",
    "detailed_emissions = output_df[output_df[\"Parameters\"] == \"Emissions\"]\n",
    "# hello can we please check that the emissions parameter covers everything \n",
    "# this should add to totco2\n",
    "# the original gets everything where the commodity has a co2 in it but excludes all the totco2 \n",
    "\n",
    "\n",
    "detailed_emissions = (\n",
    "    detailed_emissions\n",
    "    .groupby(standard_group_categories + [\"Sector\"])\n",
    "    .sum(\"PV\")\n",
    "    .reset_index()\n",
    ")\n",
    "detailed_emissions[\"PV\"] /= 1000\n",
    "\n",
    "g = sns.relplot(\n",
    "    data = detailed_emissions, \n",
    "    x = \"Period\", y = \"PV\", hue = \"Scenario\",\n",
    "    kind = \"line\",\n",
    "    col = \"Sector\", \n",
    "    col_wrap = 5,\n",
    "    facet_kws={'sharey': False}\n",
    ")\n",
    "g.figure.suptitle(\"Emissions by Sector\", y = 1.02, size = 20)\n",
    "g.set_ylabels(\"MT CO2\")\n",
    "g.set_xlabels(\"Year\")\n",
    "\n",
    "g.set_titles(col_template=\"{col_name}\", size = 14)\n",
    "g\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMISSIONS BY FUEL\n",
    "\n",
    "\n",
    "detailed_emissions = output_df[output_df[\"Parameters\"] == \"Emissions\"]\n",
    "# hello can we please check that the emissions parameter covers everything \n",
    "# this should add to totco2\n",
    "# the original gets everything where the commodity has a co2 in it but excludes all the totco2 \n",
    "\n",
    "\n",
    "detailed_emissions = (\n",
    "    detailed_emissions\n",
    "    .groupby(standard_group_categories + [\"Fuel\"])\n",
    "    .sum(\"PV\")\n",
    "    .reset_index()\n",
    ")\n",
    "detailed_emissions[\"PV\"] /= 1000\n",
    "\n",
    "g = sns.relplot(\n",
    "    data = detailed_emissions, \n",
    "    x = \"Period\", y = \"PV\", hue = \"Scenario\",\n",
    "    kind = \"line\",\n",
    "    col = \"Fuel\", \n",
    "    col_wrap = 5,\n",
    "    facet_kws={'sharey': False}\n",
    ")\n",
    "g.figure.suptitle(\"Emissions by Fuel\", y = 1.02, size = 20)\n",
    "g.set_ylabels(\"MT CO2\")\n",
    "g.set_xlabels(\"Year\")\n",
    "\n",
    "g.set_titles(col_template=\"{col_name}\", size = 14)\n",
    "g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENERGY DEMAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELECTRICITY DEMAND \n",
    "\n",
    "ele_demand = fuel_use_df[fuel_use_df[\"Parameters\"] == \"Fuel Consumption\"]\n",
    "ele_demand = ele_demand[ele_demand[\"Fuel\"] == \"Electricity\"]\n",
    "\n",
    "\n",
    "ele_demand = (\n",
    "    ele_demand\n",
    "    .groupby(standard_group_categories + [\"Fuel\"])\n",
    "    .sum(\"PV\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "ele_demand[\"PV\"] /= 3.6\n",
    "ele_demand[\"Unit\"] = \"TWh\"\n",
    "\n",
    "sns.relplot(\n",
    "    data = ele_demand, \n",
    "    x = \"Period\", y = \"PV\", hue = \"Scenario\",\n",
    "    kind = \"line\"    \n",
    ")\n",
    "\n",
    "plt.title(\"Total ele demand\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"TWh\") # not co2e?? \n",
    "plt.show()\n",
    "\n",
    "ele_demand\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELECTRICIY DEMAND BY SECTOR\n",
    "\n",
    "ele_demand = fuel_use_df[fuel_use_df[\"Parameters\"] == \"Fuel Consumption\"]\n",
    "ele_demand = ele_demand[ele_demand[\"Fuel\"] == \"Electricity\"]\n",
    "\n",
    "\n",
    "ele_demand = (\n",
    "    ele_demand\n",
    "    .groupby(standard_group_categories + [\"Sector\"])\n",
    "    .sum(\"PV\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "ele_demand[\"PV\"] /= 3.6\n",
    "ele_demand[\"Unit\"] = \"TWh\"\n",
    "\n",
    "g = sns.relplot(\n",
    "    data = ele_demand, \n",
    "    x = \"Period\", y = \"PV\", hue = \"Scenario\",\n",
    "    kind = \"line\",\n",
    "    col = \"Sector\", \n",
    "    col_wrap = 5,\n",
    "    facet_kws={'sharey': False}\n",
    ")\n",
    "g.figure.suptitle(\"Electricity Demand by Sector\", y = 1.1, size = 20)\n",
    "g.set_titles(col_template=\"{col_name}\", size = 14)\n",
    "plt.ylabel(\"TWh\")\n",
    "\n",
    "g\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELECTRICIY DEMAND BY SUBSECTOR\n",
    "\n",
    "ele_demand = fuel_use_df[fuel_use_df[\"Parameters\"] == \"Fuel Consumption\"]\n",
    "ele_demand = ele_demand[ele_demand[\"Fuel\"] == \"Electricity\"]\n",
    "\n",
    "\n",
    "ele_demand = (\n",
    "    ele_demand\n",
    "    .groupby(standard_group_categories + [\"Subsector\"])\n",
    "    .sum(\"PV\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "ele_demand[\"PV\"] /= 3.6\n",
    "ele_demand[\"Unit\"] = \"TWh\"\n",
    "\n",
    "g = sns.relplot(\n",
    "    data = ele_demand, \n",
    "    x = \"Period\", y = \"PV\", hue = \"Scenario\",\n",
    "    kind = \"line\",\n",
    "    col = \"Subsector\", \n",
    "    col_wrap = 5,\n",
    "    facet_kws={'sharey': True}\n",
    "    # facet_kws={'sharey': False}\n",
    ")\n",
    "g.figure.suptitle(\"Electricity Demand by Sector\", y = 1.01, size = 20)\n",
    "g.set_titles(col_template=\"{col_name}\", size = 14)\n",
    "plt.ylabel(\"TWh\")\n",
    "\n",
    "g\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SERVICE DEMAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "def create_facet_chart(df, row_param, col_param):\n",
    "    # Remove any empty or nan values\n",
    "    df = df.dropna(subset=[row_param, col_param, 'Period', 'PV'])\n",
    "    \n",
    "    # Create a figure with subplots\n",
    "    fig = px.bar(df,\n",
    "                 x='Period',\n",
    "                 y='PV',\n",
    "                 color='Scenario',\n",
    "                 facet_row=row_param,\n",
    "                 facet_col=col_param,\n",
    "                 barmode='group',\n",
    "                 height=250 * df[row_param].nunique(),  # Adjust height based on number of rows\n",
    "                 width=250 * df[col_param].nunique())   # Adjust width based on number of columns\n",
    "    \n",
    "    # Update layout for better readability\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=50, r=50, t=50, b=50),\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"right\",\n",
    "            x=1\n",
    "        ),\n",
    "        # Force same y-axis range across all subplots\n",
    "        yaxis=dict(matches=None)\n",
    "    )\n",
    "    \n",
    "    # Update axes labels and format\n",
    "    fig.update_xaxes(title_text=\"Period\", tickangle=45)\n",
    "    fig.update_yaxes(title_text=\"PV\")\n",
    "    \n",
    "    # Update subplot titles\n",
    "    for annotation in fig.layout.annotations:\n",
    "        annotation.text = annotation.text.split(\"=\")[1]  # Remove the variable name from subplot titles\n",
    "    \n",
    "    # Ensure consistent y-axis ranges across facets\n",
    "    y_max = df['PV'].max() * 1.1  # Add 10% padding\n",
    "    fig.update_yaxes(range=[0, y_max])\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Define the layout\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Energy System Dashboard\", \n",
    "            style={'textAlign': 'center', 'margin-bottom': '20px'}),\n",
    "    \n",
    "    html.Div([\n",
    "        dcc.Graph(id='facet-chart',\n",
    "                 config={'displayModeBar': True,\n",
    "                        'scrollZoom': True,\n",
    "                        'modeBarButtonsToRemove': ['lasso2d', 'select2d']})\n",
    "    ], style={'margin': '20px'})\n",
    "])\n",
    "\n",
    "# Callback to update the chart\n",
    "@app.callback(\n",
    "    Output('facet-chart', 'figure'),\n",
    "    [Input('facet-chart', 'relayoutData')]\n",
    ")\n",
    "def update_chart(relayout_data):\n",
    "    return create_facet_chart(df, 'Parameters', 'Fuel')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Data preprocessing\n",
    "    # df = df.sort_values(['Parameters', 'Fuel', 'Period'])\n",
    "    # Remove any duplicates\n",
    "    # df = df.drop_duplicates(['Parameters', 'Fuel', 'Period', 'Scenario'])\n",
    "    # Remove rows where Fuel is NaN\n",
    "    # df = df[df['Fuel'].notna()]\n",
    "    \n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROAD TRANSPORT ENERGY SERVICE DEMAND - TOTAL\n",
    "\n",
    "# copy above stuff and get a bunch of areas on how this is being filled \n",
    "\n",
    "# this is missing biofuel which is a problem. It looks like biofuel was not added correctly.\n",
    "# surely we should just add biofuel like any other fuel with prices and efficiencies and EFs and everything\n",
    "\n",
    "\n",
    "vkt_demand = output_df[output_df[\"Parameters\"] == \"Distance Travelled\"]\n",
    "\n",
    "vkt_demand = (\n",
    "    vkt_demand.groupby(standard_group_categories + [\"Fuel\"])\n",
    "    .sum(\"PV\")\n",
    "    .reset_index()\n",
    ")\n",
    "vkt_demand\n",
    "\n",
    "g = sns.FacetGrid(vkt_demand, col='Scenario', aspect = 1.5)  \n",
    "\n",
    "# Map the plotting function\n",
    "g.map_dataframe(stacked_area, \n",
    "    time_col='Period', \n",
    "    value_col='PV', \n",
    "    category_col='Fuel'\n",
    ")\n",
    "\n",
    "g.figure.suptitle('VKT Demand', y=1.02)\n",
    "g.add_legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "g.set_xlabels(\"Year\")\n",
    "g.set_ylabels(\"Billion VKT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROAD TRANSPORT ENERGY SERVICE DEMAND BY VEHICLE\n",
    "\n",
    " \n",
    "vkt_demand = output_df[output_df[\"Parameters\"] == \"Distance Travelled\"]\n",
    "\n",
    "vkt_demand = (\n",
    "    vkt_demand.groupby(standard_group_categories + [\"Fuel\", \"Enduse\"])\n",
    "    .sum(\"PV\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "g = sns.FacetGrid(vkt_demand, col='Scenario', row = 'Enduse', aspect = 1.5, sharey=False)  \n",
    "\n",
    "\n",
    "\n",
    "def stacked_area(data, time_col, value_col, category_col, color=None, **kwargs):\n",
    "    # Sort the categories to ensure consistent order\n",
    "    categories = sorted(data[category_col].unique())\n",
    "    \n",
    "    pivoted = data.pivot_table(\n",
    "        index=time_col, \n",
    "        columns=category_col, \n",
    "        values=value_col,\n",
    "        aggfunc='sum'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    # Ensure columns are in the same order as categories\n",
    "    pivoted = pivoted[categories]\n",
    "    \n",
    "    # Have to do really weird annoying colour hacks here. There must be an easier way?? \n",
    "    colors = {\n",
    "        'Diesel': '#1e88e5',\n",
    "        'Electricity': '#43a047',\n",
    "        'Petrol': '#ff7043',\n",
    "        'LPG': 'red'\n",
    "    }\n",
    "    \n",
    "    # Use the same order for colors as the data\n",
    "    color_list = [colors[cat] for cat in categories]\n",
    "    \n",
    "    plt.stackplot(\n",
    "        pivoted.index, \n",
    "        pivoted.T,\n",
    "        labels=categories,  # Use same category order\n",
    "        colors=color_list,  # Use matched colors\n",
    "        alpha=0.8, \n",
    "    )\n",
    "\n",
    "# Map the plotting function\n",
    "g.map_dataframe(stacked_area, \n",
    "    time_col='Period', \n",
    "    value_col='PV', \n",
    "    category_col='Fuel'\n",
    ")\n",
    "\n",
    "g.figure.suptitle('Meeting VKT demand', y=1.02)\n",
    "g.add_legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "g.set_xlabels(\"Year\")\n",
    "g.set_ylabels(\"Billion VKT\")\n",
    "\n",
    "g.set_titles('{row_name} - {col_name}')\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESD 2: VAR_DEM\n",
    "\n",
    "\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELECTRICITY DEMAND BY TIMESLICE \n",
    "\n",
    "\n",
    "# want to display the timeslices we have available\n",
    "# to do this need to plug into what each timeslice represents \n",
    "\n",
    "# Currently setup like this: (24 slices)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Season\tWeekly\tDayNite\n",
    "\n",
    "SUM     WK-\t      D\n",
    "FAL     WE-\t      N\n",
    "WIN     \t      P\n",
    "SPR     \t\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# a couple possibilities for how to represent: \n",
    "\n",
    "# average of demand per year, where we split out each bar by the number of hours in it then fill each bar with the elecricity use for that period \n",
    "# this should come off of base year but we can take the future years to see what changes \n",
    "\n",
    "\n",
    "# peak demand in GW each year (timeseries)\n",
    "# should try align this with the EA official peak data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PEAK DEMAND \n",
    "\n",
    "#1: ele by timeslice \n",
    "#2: timeslice size\n",
    "#3: calculate avg load \n",
    "#4: take highest load per year\n",
    "\n",
    "# is there some way that this is adjusted further? some kind of peak \n",
    "\n",
    "# want to also include peak support capacity \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVERYTHING BELOW THIS LINE IS BAD AND OLD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agriculture\n",
    "\n",
    "## energy demand? \n",
    "\n",
    "## technology use? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sector_demand_chart(sector, facet_variable, df = clean_df):\n",
    "    demand_cols = [\"Scenario\", \"Period\", \"Sector\", \"Unit\", facet_variable]    \n",
    "\n",
    "    chart_data = aggregate_demand_data(df, demand_cols)\n",
    "    chart_data = chart_data[chart_data[\"Sector\"] == sector]\n",
    "\n",
    "    unit = chart_data[\"Unit\"].unique()[0]\n",
    "\n",
    "    g = sns.relplot(\n",
    "        data = chart_data, \n",
    "        x = \"Period\", y = \"Value\", hue = \"Scenario\",\n",
    "        kind = \"line\",\n",
    "        col = facet_variable,         \n",
    "        col_wrap = 4,\n",
    "        facet_kws={'sharey': False}\n",
    "        )\n",
    "    \n",
    "    g.figure.suptitle(f\"{sector} energy demand by {facet_variable}\", y = 1.05, size = 20)\n",
    "    g.set_titles(col_template=\"{col_name}\", size = 14)\n",
    "    g.set_axis_labels(\"Year\", unit)   \n",
    "\n",
    "\n",
    "def make_sector_tech_x_fuel_chart(sector, df = clean_df):\n",
    "\n",
    "    demand_cols = [\"Scenario\", \"Period\", \"Sector\", \"Unit\", \"Technology_Group\", \"Fuel\"]   \n",
    "\n",
    "    chart_data = aggregate_demand_data(df, demand_cols)\n",
    "    \n",
    "    chart_data = chart_data[chart_data[\"Sector\"] == sector]\n",
    "\n",
    "    unit = chart_data[\"Unit\"].unique()[0]\n",
    "\n",
    "    g = sns.relplot(\n",
    "        data = chart_data, \n",
    "        x = \"Period\", y = \"Value\", hue = \"Scenario\",\n",
    "        kind = \"line\",\n",
    "        col = \"Technology_Group\",         \n",
    "        row = \"Fuel\",\n",
    "        # col_wrap = 4,\n",
    "        facet_kws={'sharey': False}\n",
    "        )\n",
    "    \n",
    "    g.figure.suptitle(f\"{sector} energy demand\", y = 1.05, size = 20)\n",
    "    g.set_titles(col_template=\"{col_name}\", size = 14)\n",
    "    g.set_axis_labels(\"Year\", unit)   \n",
    "    \n",
    "\n",
    "def make_sector_demand_charts(sector):\n",
    "    for variable in [\"Fuel\", \"Subsector\", \"Technology_Group\"]:\n",
    "        make_sector_demand_chart(sector, variable)\n",
    "    # make_sector_tech_x_fuel_chart(sector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "want ESD (ie control for the efficiency of fuel used) so we can get the purest form of activity demand\n",
    "\n",
    "then we would see how that is serviced just to get a better intuition \n",
    "\n",
    "for now a better approach might be to get a technology group X fuel split? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
